{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5d3102-d278-4cc0-aef8-a217ab73e002",
   "metadata": {},
   "source": [
    "# Stage 06 — Data Preprocessing (ASML)\n",
    "Load raw → clean (fill/drop/normalize) → compare → save cleaned dataset to `project/data/processed/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec40fe-eaca-44dd-b1bb-587e83332f0c",
   "metadata": {},
   "source": [
    "Imports, paths, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88554100-8520-4852-b064-4ff087cc4734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/raw'),\n",
       " WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/processed'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Resolve project root when running from project/notebooks\n",
    "project_root = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd().resolve()\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "from storage import env_paths, write_df, read_df\n",
    "from cleaning import fill_missing_median, drop_missing, normalize_data\n",
    "\n",
    "RAW_DIR, PROC_DIR = env_paths(project_root)\n",
    "RAW_DIR, PROC_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fac56-348b-4270-a126-40f7928c17ca",
   "metadata": {},
   "source": [
    "Load the latest raw ASML CSV (from Stage 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761cc62f-cbef-4a10-91f2-e58077e0e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw file: api_yfinance_ASML_20250816-0017.csv\n",
      "(1256, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>376.660004</td>\n",
       "      <td>380.500000</td>\n",
       "      <td>376.250000</td>\n",
       "      <td>378.510010</td>\n",
       "      <td>364.919250</td>\n",
       "      <td>428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>383.609985</td>\n",
       "      <td>383.980011</td>\n",
       "      <td>376.989990</td>\n",
       "      <td>377.220001</td>\n",
       "      <td>363.675568</td>\n",
       "      <td>466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>380.390015</td>\n",
       "      <td>380.429993</td>\n",
       "      <td>373.959991</td>\n",
       "      <td>374.940002</td>\n",
       "      <td>361.477417</td>\n",
       "      <td>354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>369.540009</td>\n",
       "      <td>373.380005</td>\n",
       "      <td>368.380005</td>\n",
       "      <td>372.170013</td>\n",
       "      <td>358.806976</td>\n",
       "      <td>498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>366.149994</td>\n",
       "      <td>372.130005</td>\n",
       "      <td>365.540009</td>\n",
       "      <td>372.119995</td>\n",
       "      <td>358.758667</td>\n",
       "      <td>605400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        open        high         low       close  adjusted_close  \\\n",
       "0 2020-08-17  376.660004  380.500000  376.250000  378.510010      364.919250   \n",
       "1 2020-08-18  383.609985  383.980011  376.989990  377.220001      363.675568   \n",
       "2 2020-08-19  380.390015  380.429993  373.959991  374.940002      361.477417   \n",
       "3 2020-08-20  369.540009  373.380005  368.380005  372.170013      358.806976   \n",
       "4 2020-08-21  366.149994  372.130005  365.540009  372.119995      358.758667   \n",
       "\n",
       "   volume  \n",
       "0  428200  \n",
       "1  466500  \n",
       "2  354400  \n",
       "3  498200  \n",
       "4  605400  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = sorted(RAW_DIR.glob(\"api_*ASML_*.csv\"))\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"No ASML raw CSV found in project/data/raw/. Run Stage 04 first.\")\n",
    "raw_path = candidates[-1]\n",
    "print(\"Using raw file:\", raw_path.name)\n",
    "\n",
    "df_raw = pd.read_csv(raw_path, parse_dates=[\"date\"])\n",
    "print(df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87079960-5a49-4ac4-baad-0278db147ffb",
   "metadata": {},
   "source": [
    "Quick inspection (missingness, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ed0270-cb32-4356-9648-36c1a58069f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes:\n",
      " date              datetime64[ns]\n",
      "open                     float64\n",
      "high                     float64\n",
      "low                      float64\n",
      "close                    float64\n",
      "adjusted_close           float64\n",
      "volume                     int64\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      " date              0\n",
      "open              0\n",
      "high              0\n",
      "low               0\n",
      "close             0\n",
      "adjusted_close    0\n",
      "volume            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dtypes:\\n\", df_raw.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", df_raw.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fc054-d58f-4f9a-be63-01e48a2fca6a",
   "metadata": {},
   "source": [
    "Cleaning step 1: drop rows missing critical keys (e.g., date, close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513eeb6a-2fbe-4156-8421-9aadd8de6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop_missing on critical: (1256, 7)\n"
     ]
    }
   ],
   "source": [
    "critical = [\"date\", \"close\"]\n",
    "df1 = drop_missing(df_raw, cols=critical)\n",
    "print(\"After drop_missing on critical:\", df1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674985bf-f0f7-4903-aad5-6f5e569808d9",
   "metadata": {},
   "source": [
    "Cleaning step 2: fill remaining numeric gaps with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f8e4a1-1d3c-48cc-8e60-dd9eb7c4300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fill_missing_median: (1256, 7)\n",
      "Medians used: {'open': 676.375, 'high': 683.5450134277344, 'low': 669.6549987792969, 'close': 678.2850036621094, 'adjusted_close': 666.6448364257812, 'volume': 989600.0}\n",
      "Remaining missing values:\n",
      " date              0\n",
      "open              0\n",
      "high              0\n",
      "low               0\n",
      "close             0\n",
      "adjusted_close    0\n",
      "volume            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2, medians = fill_missing_median(df1)  # defaults to all numeric cols\n",
    "print(\"After fill_missing_median:\", df2.shape)\n",
    "print(\"Medians used:\", medians)\n",
    "print(\"Remaining missing values:\\n\", df2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c90d9-e3d8-417f-80e5-669c17979847",
   "metadata": {},
   "source": [
    "Cleaning step 3: normalize numeric columns (minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac875c5-9db9-4291-a887-c2a20bdc80c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization stats (first few): {}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>376.660004</td>\n",
       "      <td>380.500000</td>\n",
       "      <td>376.250000</td>\n",
       "      <td>378.510010</td>\n",
       "      <td>364.919250</td>\n",
       "      <td>428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>383.609985</td>\n",
       "      <td>383.980011</td>\n",
       "      <td>376.989990</td>\n",
       "      <td>377.220001</td>\n",
       "      <td>363.675568</td>\n",
       "      <td>466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>380.390015</td>\n",
       "      <td>380.429993</td>\n",
       "      <td>373.959991</td>\n",
       "      <td>374.940002</td>\n",
       "      <td>361.477417</td>\n",
       "      <td>354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>369.540009</td>\n",
       "      <td>373.380005</td>\n",
       "      <td>368.380005</td>\n",
       "      <td>372.170013</td>\n",
       "      <td>358.806976</td>\n",
       "      <td>498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>366.149994</td>\n",
       "      <td>372.130005</td>\n",
       "      <td>365.540009</td>\n",
       "      <td>372.119995</td>\n",
       "      <td>358.758667</td>\n",
       "      <td>605400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        open        high         low       close  adjusted_close  \\\n",
       "0 2020-08-17  376.660004  380.500000  376.250000  378.510010      364.919250   \n",
       "1 2020-08-18  383.609985  383.980011  376.989990  377.220001      363.675568   \n",
       "2 2020-08-19  380.390015  380.429993  373.959991  374.940002      361.477417   \n",
       "3 2020-08-20  369.540009  373.380005  368.380005  372.170013      358.806976   \n",
       "4 2020-08-21  366.149994  372.130005  365.540009  372.119995      358.758667   \n",
       "\n",
       "   volume  \n",
       "0  428200  \n",
       "1  466500  \n",
       "2  354400  \n",
       "3  498200  \n",
       "4  605400  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3, zstats = normalize_data(df2, method=\"minimax\")  # defaults to all numeric cols\n",
    "print(\"Normalization stats (first few):\", dict(list(zstats.items())[:3]))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5d920-e630-4872-9129-1323e5f109ae",
   "metadata": {},
   "source": [
    "Compare original vs cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3d8566-af23-4a55-b267-6e64b6530d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1256, 7) → (1256, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_na</th>\n",
       "      <th>clean_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjusted_close</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                orig_na  clean_na\n",
       "date                  0         0\n",
       "open                  0         0\n",
       "high                  0         0\n",
       "low                   0         0\n",
       "close                 0         0\n",
       "adjusted_close        0         0\n",
       "volume                0         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quick_compare(orig: pd.DataFrame, clean: pd.DataFrame):\n",
    "    print(\"Shapes:\", orig.shape, \"→\", clean.shape)\n",
    "    orig_na = orig.isna().sum()\n",
    "    clean_na = clean.isna().sum()\n",
    "    comp = pd.DataFrame({\"orig_na\": orig_na, \"clean_na\": clean_na})\n",
    "    return comp\n",
    "\n",
    "compare_na = quick_compare(df_raw, df3)\n",
    "compare_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52cf0f-5e12-40a3-a884-04a29abab610",
   "metadata": {},
   "source": [
    "Save the cleaned dataset into project/data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ff7875-d44d-421e-8b56-3273efe34a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/processed/asml_cleaned_20250818-2218.csv'),\n",
       " WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/processed/asml_cleaned_20250818-2218.parquet'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "clean_csv  = PROC_DIR / f\"asml_cleaned_{stamp}.csv\"\n",
    "clean_parq = PROC_DIR / f\"asml_cleaned_{stamp}.parquet\"\n",
    "\n",
    "write_df(df3, clean_csv)\n",
    "write_df(df3, clean_parq)\n",
    "\n",
    "clean_csv, clean_parq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612f7c1-7465-4d1e-9df2-b8d4706b63d1",
   "metadata": {},
   "source": [
    "Reload & validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83faf746-c6b9-425a-82ae-16fb167301e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded shapes: (1256, 7) (1256, 7)\n",
      "CSV dtypes:\n",
      " date              datetime64[ns]\n",
      "open                     float64\n",
      "high                     float64\n",
      "low                      float64\n",
      "close                    float64\n",
      "adjusted_close           float64\n",
      "volume                     int64\n",
      "dtype: object\n",
      "PARQ dtypes:\n",
      " date              datetime64[ns]\n",
      "open                     float64\n",
      "high                     float64\n",
      "low                      float64\n",
      "close                    float64\n",
      "adjusted_close           float64\n",
      "volume                     int64\n",
      "dtype: object\n",
      "Validation OK.\n"
     ]
    }
   ],
   "source": [
    "df_csv = read_df(clean_csv, parse_dates=[\"date\"])\n",
    "df_parq = read_df(clean_parq)\n",
    "\n",
    "print(\"Reloaded shapes:\", df_csv.shape, df_parq.shape)\n",
    "print(\"CSV dtypes:\\n\", df_csv.dtypes)\n",
    "print(\"PARQ dtypes:\\n\", df_parq.dtypes)\n",
    "\n",
    "assert df_csv.shape == df3.shape, \"CSV shape mismatch\"\n",
    "assert df_parq.shape == df3.shape, \"Parquet shape mismatch\"\n",
    "print(\"Validation OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f6ede-63cf-4ea5-9be9-5bb9bf05cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assumptions & notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a566ef-1997-4aaa-aaa5-6cffcc90ec36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '—' (U+2014) (3578465075.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m- **Risks:** Over-normalization can hinder interpretability; medians may shift over time—consider refit cadence.\u001b[39m\n                                                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '—' (U+2014)\n"
     ]
    }
   ],
   "source": [
    "## Assumptions & Cleaning Notes\n",
    "- **Critical columns:** `date` and `close` are required; rows missing either are dropped.\n",
    "- **Fill strategy:** Remaining numeric columns are filled with **median** (robust to outliers).\n",
    "- **Scaling:** Applied **minimax normalization** to numeric columns for modeling comparability; store stats for reproducibility.\n",
    "- **Non-numeric columns:** Left unchanged.\n",
    "- **Reproducibility:** All paths are environment-driven; outputs saved under `project/data/processed/` with timestamps.\n",
    "- **Risks:** Over-normalization can hinder interpretability; medians may shift over time—consider refit cadence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6c89a-0a6f-4d57-94f0-8c0b4d733c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cb537-c896-48fc-b7c8-269faa72407e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ASML env)",
   "language": "python",
   "name": "asml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
