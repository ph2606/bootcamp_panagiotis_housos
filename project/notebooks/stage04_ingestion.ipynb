{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89ada85-91af-41ff-a3f4-a50e06a60666",
   "metadata": {},
   "source": [
    "# Stage 04 — Data Acquisition & Ingestion (ASML)\n",
    "API pull (Alpha Vantage or yfinance fallback) + scrape Wikipedia table; validate; save to `project/data/raw`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c882a6-4fd0-4315-8500-8b162c8411eb",
   "metadata": {},
   "source": [
    "Imports, paths, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc9f632-c85a-457d-b50f-bd7c6166690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\melin\\OneDrive\\Desktop\\nyu\\python\\bootcamp_panagiotis_housos\\project\n",
      "Using RAW_DIR: C:\\Users\\melin\\OneDrive\\Desktop\\nyu\\python\\bootcamp_panagiotis_housos\\project\\data\\raw\n",
      "ALPHAVANTAGE key present: False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, sys, time, json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Resolve project root when running from project/notebooks\n",
    "project_root = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd().resolve()\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "DATA_DIR = project_root / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "ALPHA_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "\n",
    "def now_stamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "def validate_df(df: pd.DataFrame, required_cols: list[str] | None = None, type_hints: dict[str, str] | None = None):\n",
    "    \"\"\"Minimal, high-value checks (schema, types, completeness). Robust to weird dtypes/2-D columns.\"\"\"\n",
    "    msgs = {}\n",
    "\n",
    "    # 1) Schema\n",
    "    if required_cols:\n",
    "        missing = [c for c in required_cols if c not in df.columns]\n",
    "        if missing:\n",
    "            msgs[\"missing_cols\"] = f\"Missing columns: {missing}\"\n",
    "\n",
    "    # 2) Types/coercion (defensive)\n",
    "    if type_hints:\n",
    "        for col, t in type_hints.items():\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            s = df[col]\n",
    "\n",
    "            # If somehow 2-D (e.g., DataFrame slipped in), squeeze to 1-D\n",
    "            if hasattr(s, \"ndim\") and getattr(s, \"ndim\", 1) > 1:\n",
    "                try:\n",
    "                    s = s.squeeze()  # try to collapse to 1-D\n",
    "                except Exception:\n",
    "                    # fall back to first column if it's a DataFrame\n",
    "                    try:\n",
    "                        s = s.iloc[:, 0]\n",
    "                    except Exception:\n",
    "                        msgs.setdefault(\"type_errors\", []).append(f\"{col}: could not reduce to 1-D\")\n",
    "                        continue\n",
    "\n",
    "            if isinstance(s, pd.DataFrame):\n",
    "                # Last resort: pick first column\n",
    "                s = s.iloc[:, 0]\n",
    "\n",
    "            if t.startswith(\"datetime\"):\n",
    "                try:\n",
    "                    s = pd.to_datetime(s, errors=\"coerce\")\n",
    "                except Exception as e:\n",
    "                    msgs.setdefault(\"type_errors\", []).append(f\"{col}: {e}\")\n",
    "\n",
    "            elif t in (\"float\", \"float64\"):\n",
    "                # If not numeric, clean common symbols then coerce\n",
    "                if not pd.api.types.is_numeric_dtype(s):\n",
    "                    s = (\n",
    "                        s.astype(str)\n",
    "                         .str.replace(r\"\\[.*?\\]\", \"\", regex=True)\n",
    "                         .str.replace(\",\", \"\", regex=False)\n",
    "                         .str.replace(\"%\", \"\", regex=False)\n",
    "                         .str.replace(\"$\", \"\", regex=False)\n",
    "                         .str.strip()\n",
    "                    )\n",
    "                s = pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "            elif t in (\"int\", \"int64\"):\n",
    "                s = pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "            # write back\n",
    "            df[col] = s\n",
    "\n",
    "    # 3) Completeness & shape\n",
    "    msgs[\"shape\"] = f\"{df.shape}\"\n",
    "    msgs[\"na_counts\"] = {k: int(v) for k, v in df.isna().sum().to_dict().items()}\n",
    "\n",
    "    return df, msgs\n",
    "\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Using RAW_DIR:\", RAW_DIR)\n",
    "print(\"ALPHAVANTAGE key present:\", bool(ALPHA_KEY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd8c69-2d0d-4f4b-8531-82b5d124acac",
   "metadata": {},
   "source": [
    "API pull (Alpha Vantage primary, yfinance fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696c1d24-fbd2-40ab-8174-a046f37beb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Vantage failed or key missing → No ALPHAVANTAGE_API_KEY; using yfinance fallback.\n",
      "date              datetime64[ns]\n",
      "open                     float64\n",
      "high                     float64\n",
      "low                      float64\n",
      "close                    float64\n",
      "adjusted_close           float64\n",
      "volume                     int64\n",
      "dtype: object\n",
      "Validation: {'shape': '(1256, 7)', 'na_counts': {'date': 0, 'open': 0, 'high': 0, 'low': 0, 'close': 0, 'adjusted_close': 0, 'volume': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/raw/api_yfinance_ASML_20250816-0017.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_alphavantage_daily(symbol: str, api_key: str, outputsize: str = \"compact\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    TIME_SERIES_DAILY_ADJUSTED for US symbol (e.g., ASML).\n",
    "    outputsize: 'compact' (100) or 'full' (20+ years)\n",
    "    \"\"\"\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
    "        \"symbol\": symbol,\n",
    "        \"outputsize\": outputsize,\n",
    "        \"datatype\": \"json\",\n",
    "        \"apikey\": api_key,\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    js = r.json()\n",
    "    if \"Time Series (Daily)\" not in js:\n",
    "        raise ValueError(f\"Unexpected response keys: {list(js.keys())[:5]}\")\n",
    "    ts = js[\"Time Series (Daily)\"]\n",
    "    # Build DataFrame\n",
    "    recs = []\n",
    "    for d, vals in ts.items():\n",
    "        recs.append({\n",
    "            \"date\": d,\n",
    "            \"open\": float(vals[\"1. open\"]),\n",
    "            \"high\": float(vals[\"2. high\"]),\n",
    "            \"low\": float(vals[\"3. low\"]),\n",
    "            \"close\": float(vals[\"4. close\"]),\n",
    "            \"adjusted_close\": float(vals[\"5. adjusted close\"]),\n",
    "            \"volume\": float(vals[\"6. volume\"]),\n",
    "            # \"dividend_amount\": float(vals[\"7. dividend amount\"]),\n",
    "            # \"split_coefficient\": float(vals[\"8. split coefficient\"]),\n",
    "        })\n",
    "    df = pd.DataFrame(recs)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def fetch_yfinance_daily(symbol: str, period: str = \"5y\", interval: str = \"1d\") -> pd.DataFrame:\n",
    "    import yfinance as yf\n",
    "\n",
    "    df = yf.download(\n",
    "        symbol,\n",
    "        period=period,\n",
    "        interval=interval,\n",
    "        auto_adjust=False,\n",
    "        progress=False,\n",
    "        group_by=\"column\",  # keep OHLCV grouped; we'll flatten next\n",
    "    )\n",
    "\n",
    "    # If yfinance returned MultiIndex columns (e.g., ('Close','ASML')), flatten them\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        # If it’s a single ticker (one unique second-level), just drop the ticker level\n",
    "        if df.columns.nlevels == 2 and len(df.columns.get_level_values(1).unique()) == 1:\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "        else:\n",
    "            # Otherwise, join levels with underscore\n",
    "            df.columns = [\"_\".join(map(str, tup)).strip() for tup in df.columns.to_flat_index()]\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Normalize column names to snake_case\n",
    "    df.columns = [str(c).strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    # Unify common synonyms\n",
    "    if \"adj_close\" in df.columns and \"adjusted_close\" not in df.columns:\n",
    "        df = df.rename(columns={\"adj_close\": \"adjusted_close\"})\n",
    "    if \"datetime\" in df.columns and \"date\" not in df.columns:\n",
    "        df = df.rename(columns={\"datetime\": \"date\"})\n",
    "    if \"index\" in df.columns and \"date\" not in df.columns:\n",
    "        df = df.rename(columns={\"index\": \"date\"})\n",
    "\n",
    "    # Parse types\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\", \"adjusted_close\", \"volume\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Keep only the columns we care about (those that exist)\n",
    "    needed = [\"date\", \"open\", \"high\", \"low\", \"close\", \"adjusted_close\", \"volume\"]\n",
    "    df = df[[c for c in needed if c in df.columns]].sort_values(\"date\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Choose primary source\n",
    "SYMBOL = \"ASML\"\n",
    "try:\n",
    "    if not ALPHA_KEY:\n",
    "        raise RuntimeError(\"No ALPHAVANTAGE_API_KEY; using yfinance fallback.\")\n",
    "    api_df = fetch_alphavantage_daily(SYMBOL, ALPHA_KEY, outputsize=\"compact\")\n",
    "    src = \"alphavantage\"\n",
    "except Exception as e:\n",
    "    print(\"Alpha Vantage failed or key missing →\", e)\n",
    "    api_df = fetch_yfinance_daily(SYMBOL, period=\"5y\", interval=\"1d\")\n",
    "    src = \"yfinance\"\n",
    "\n",
    "# Validate and save\n",
    "req = [\"date\",\"close\",\"adjusted_close\",\"volume\"]\n",
    "types = {\n",
    "    \"date\": \"datetime64[ns]\",\n",
    "    \"close\": \"float\",\n",
    "    \"adjusted_close\": \"float\",\n",
    "    \"volume\": \"float\",   # treat as float; can cast to Int64 later if you want\n",
    "}\n",
    "api_df, msgs = validate_df(api_df, req, types)\n",
    "print(api_df.dtypes)\n",
    "print(\"Validation:\", msgs)\n",
    "\n",
    "\n",
    "stamp = now_stamp()\n",
    "api_path = RAW_DIR / f\"api_{src}_{SYMBOL}_{stamp}.csv\"\n",
    "api_df.to_csv(api_path, index=False)\n",
    "api_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4a5a3-c23d-466e-8b1d-75c7d84274d2",
   "metadata": {},
   "source": [
    "Scrape a small permitted table (Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9512e43c-df9d-4d89-9937-62d06603c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 tables.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/melin/OneDrive/Desktop/nyu/python/bootcamp_panagiotis_housos/project/data/raw/scrape_wikipedia_ASML_20250816-0010.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIKI_URL = \"https://en.wikipedia.org/wiki/ASML_Holding\"\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; IngestionBot/0.1; +edu-project)\"}\n",
    "resp = requests.get(WIKI_URL, headers=headers, timeout=30)\n",
    "resp.raise_for_status()\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "# Use pandas to parse HTML tables (requires lxml)\n",
    "tables = pd.read_html(StringIO(resp.text)); print(f\"Found {len(tables)} tables.\")\n",
    "\n",
    "# Pick a simple table with numeric-like content (fallback to the first wikitable-like)\n",
    "# Heuristic: choose the widest table with at least 2 columns and > 3 rows\n",
    "cand = sorted(\n",
    "    (t for t in tables if isinstance(t, pd.DataFrame) and t.shape[1] >= 2 and t.shape[0] >= 3),\n",
    "    key=lambda x: (x.shape[0]*x.shape[1]),\n",
    "    reverse=True\n",
    ")\n",
    "scrape_df = cand[0].copy() if cand else tables[0].copy()\n",
    "\n",
    "# Basic cleaning: try to coerce numeric-looking columns safely\n",
    "for c in scrape_df.columns:\n",
    "    if scrape_df[c].dtype == \"object\":\n",
    "        col = (\n",
    "            scrape_df[c].astype(str)\n",
    "            .str.replace(r\"\\[.*?\\]\", \"\", regex=True)  # drop refs like [1]\n",
    "            .str.replace(\",\", \"\", regex=False)\n",
    "            .str.replace(\"%\", \"\", regex=False)\n",
    "            .str.strip()\n",
    "        )\n",
    "        # Try numeric conversion; if not mostly numeric, keep as cleaned text\n",
    "        numeric_try = pd.to_numeric(col, errors=\"coerce\")\n",
    "        ratio_numeric = numeric_try.notna().mean()  # fraction successfully parsed\n",
    "        scrape_df[c] = numeric_try if ratio_numeric >= 0.6 else col\n",
    "\n",
    "\n",
    "# Minimal validation: non-empty, at least 2 cols\n",
    "if scrape_df.empty or scrape_df.shape[1] < 2:\n",
    "    raise ValueError(\"Scraped table is empty or too narrow.\")\n",
    "\n",
    "# Save raw CSV\n",
    "scrape_path = RAW_DIR / f\"scrape_wikipedia_ASML_{now_stamp()}.csv\"\n",
    "scrape_df.to_csv(scrape_path, index=False)\n",
    "scrape_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00567be2-d6df-4e2d-b1eb-13dfb5073dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"api_source\": \"yfinance\",\n",
      "  \"symbol\": \"ASML\",\n",
      "  \"api_file\": \"C:\\\\Users\\\\melin\\\\OneDrive\\\\Desktop\\\\nyu\\\\python\\\\bootcamp_panagiotis_housos\\\\project\\\\data\\\\raw\\\\api_yfinance_ASML_20250816-0017.csv\",\n",
      "  \"scrape_source\": \"wikipedia\",\n",
      "  \"scrape_url\": \"https://en.wikipedia.org/wiki/ASML_Holding\",\n",
      "  \"scrape_file\": \"C:\\\\Users\\\\melin\\\\OneDrive\\\\Desktop\\\\nyu\\\\python\\\\bootcamp_panagiotis_housos\\\\project\\\\data\\\\raw\\\\scrape_wikipedia_ASML_20250816-0010.csv\",\n",
      "  \"run_timestamp\": \"20250816-0019\",\n",
      "  \"validation_api\": {\n",
      "    \"shape\": \"(1256, 7)\",\n",
      "    \"na_counts\": {\n",
      "      \"date\": 0,\n",
      "      \"open\": 0,\n",
      "      \"high\": 0,\n",
      "      \"low\": 0,\n",
      "      \"close\": 0,\n",
      "      \"adjusted_close\": 0,\n",
      "      \"volume\": 0\n",
      "    }\n",
      "  },\n",
      "  \"assumptions_risks\": [\n",
      "    \"EOD data; educational use only.\",\n",
      "    \"API schema/limits may change; yfinance fallback used.\",\n",
      "    \"Scraped HTML structure may shift; table selection is heuristic.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    \"api_source\": \"yfinance\",           # or \"alphavantage\"\n",
    "    \"symbol\": \"ASML\",\n",
    "    \"api_file\": str(api_path),\n",
    "    \"scrape_source\": \"wikipedia\",\n",
    "    \"scrape_url\": \"https://en.wikipedia.org/wiki/ASML_Holding\",\n",
    "    \"scrape_file\": str(scrape_path),\n",
    "    \"run_timestamp\": now_stamp(),\n",
    "    \"validation_api\": msgs,             # from validate_df\n",
    "    \"assumptions_risks\": [\n",
    "        \"EOD data; educational use only.\",\n",
    "        \"API schema/limits may change; yfinance fallback used.\",\n",
    "        \"Scraped HTML structure may shift; table selection is heuristic.\",\n",
    "    ],\n",
    "}\n",
    "import json, pprint; print(json.dumps(doc, indent=2)[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98526b50-acf1-4e87-82b3-09eebc60ced6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
